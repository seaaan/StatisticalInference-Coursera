{
    "collab_server" : "",
    "contents" : "# Improving your statistical inferences\n\n## Introduction\n\nGoal: become a better, more efficient researcher by better understanding statistical inference. \n\nWhen you collect data, the goal is to inform scientific theories. First you have to draw valid statistical inferences and then you can draw theoretical inferences. \n\nTopics: \n* Statistical tools for inference\n* Experimental design\n* Evaluating the evidence\n* Cumulative science (replication, preregistration)\n\n## Week 1: Overview\n\nStatistical inference = use data from a *sample* to describe properties of the *population*\nE.g. test a hypothesis, calculate a CI, estimate an effect size\n\nApproaches to statistical inference: \n* Frequentist (Fisher vs Neyman-Pearson)\n* Likelihood\n* Bayesian\n\nRecommended reading: \nDienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference. Palgrave Macmillan.\nCumming, G. (2013). Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge.\nNickerson, R. S. (2000). Null hypothesis significance testing: a review of an old and continuing controversy. Psychological methods, 5(2), 241-301.\nAn accessible introduction to hypothesis testing, Type 1 and Type 2 errors, power, and p-values can be found in most textbooks, but a clear open access summary is available in:\nBanerjee, A., Chitnis, U. B., Jadhav, S. L., Bhawalkar, J. S., & Chaudhury, S. (2009). Hypothesis testing, type I and type II errors. Industrial Psychiatry Journal, 18(2), 127.\n\n### Lecture 1.1\n\nApproach to statistical inference (path of action; Neyman-Pearson frequentist): \n* Use rules to make sure that, over the long run, we won't be wrong too often\n* Tells nothing about the current test, only the long run\n\nPath of knowledge (likelihood): \n* Compare the likelihood of different hypothesis given the evidence at hand\n* E.g. given 10 flips of a coin, what are the odds that it's a fair coin\n* Calculate likelihood ratio\n* Richard Royall, underlie Bayesian statistics without relying on pirors\n\nPath of belief (Bayesion): \n* Incorporate prior beliefs about a phenomenon into your interpretation\n* Express evidence in terms of degrees of belief\n\nFisher = use p-values as a measure of evidence (rather than as a rule for the long run)\n* Neyman-Pearson is the better way to do it\n* Most people understand p-values in Fisher's way\n\n### Lecture: What is a p-value?\n\nGoal of p-value: line of defense against being fooled by randomness\n* p-values: measure of how surprising the data is, assuming there's no effect\n\nCalculating p-value: calculate a test statistic from mean, SD and n, then compare it to some kind of distribution\n* Assuming no effect means that you center the compared distribution at 0, with 1.96 and -1.96 representing 95% of the data\n* Seeing data that fails in one of the tails (> 1.96 or < -1.96 means the data is surprising, assuming there is no true effect)\n\nDefinition: probability of getting the observed or more extreme data, assuming the null hypothesis is true\n* no relation to whether the THEORY is true, only the probability of getting data that extreme\n* i.e. p = 0.04 means there is a 4% probability that you would get the observed or more extreme data, assuming the null hypothesis is actually true\n* Doesn't give you the probability that the null hypothesis is true.\n** not the probability of the null hypothesis being true, given the data\n** instead, it's the probability of the data being as or more extreme, given the null hypothesis \n\np > 0.05 doesn't mean that there is no effect, just that the data aren't surprising\n\nUsing p-values correctly: a rule to guide behavior in the long run\n* decision rule: act as if the data are not noise when p < alpha; remain uncertain/act if data is noise when p > alpha\n* this will ensure that you won't be wrong more than alpha % of the time\n\nCorrect interpretation/statement: we found a p-value < 0.05, so our data... not \"so our theory\" \n\nP-values to expect when there is a true effect vs. when there is no effect: \n* true effect: p-value distribution depends on the statistical power\n** with 50% power, half of the p values are below 0.05, >75% below 0.15\n** with 80% power, 80% of the  p values are below 0.05, >95% below 0.15\n\n* no effect: p-values are uniformly distributed (not tailed to the high end or normally distributed)\n** every p-value is equally likely (INCLUDING less than 0.05), with 5% < 0.05\n\nWhen there is no true effect, p-values are uniformly distributed. \nWhen there is a true effect, the p-value distribution depends on the power, and the higher the power, the more p-values fall below 0.05, and the steeper the p-value distribution becomes.\n\nWhen you have very high power (>95%) and observe a p-value of 0.04 to 0.05, it means the data are surprising under the null hypothesis. However, it also means that the data are EVEN MORE surprising under the alternative hypothesis, because with such high power, p-values between 0.04 and 0.05 are even less likely under the alternative hypothesis than under the null hypothesis. = Lindley's paradox\n\n### Lecture: Type 1 and Type 2 errors\n\nError control: prevent making a fool out of yourself too often in the long run\nType 1: false positive\nType 2: false negative\n\nH0: null hypothesis\nH1: alternative hypothesis\n\nalpha = probability of a significant result when the null hypothesis is true\n* type 1 error rate\nbeta  = probability of a non-significant result when the alternative hypothesis is true\n* type 2 error rate\n\n1 - beta = probability of a significant result when the alternative hypothesis is true \n* statistical power\n* i.e. probability that you'll find the significant result when it's true\n* true positive\n\n1 - alpha = probability of a non-significant result when the null hypothesis is true\n* true negative \n\nError rates = frequentist concepts, about the long run, not the particular expt\n\n            H0 true           |           H1 true\nsignif      false pos alpha      true positive 1-beta\nnonsignif   true neg 1-alpha     false neg beta\n\nExample: \n   Assume H0 and H1 have 50% probability, set alpha = 5%, 1-beta = 80%\n   \n      5  80 *  50% probability of each =  2.5   40\n      95 20                               47.5  10\n   So most likely result is to find a true negative. \n   \n   How to improve? \n   * Increase statistical power to 99% and then true positive rate becomes 49.5% but still similarly likely to true negative\n   * Find a better hypothesis (one that is more likely to be true, so H0:H1 is not 50:50)\n   \nAnother way to think about type 1 and type 2 errors: \n   Imagine a normal curve centered at 0 representing H0. Then imagine another normal curve centered at 0.35 representing H1 (effect size 0.35). Each curve represents the results you would get from experiments given that the corresponding hypothesis is true. There will be a critical value, about 0.24, where for p = 0.05, experimental results above the value are deemed positive and below are deemed negative. You can then divide the two curves into 4 segments:\n   * H0 curve, values below 0.24 = true negative\n   * H0 curve, values above 0.24 = false positive\n   * H1 curve, values below 0.24 = false negative\n   * H1 curve, values above 0.24 = true positive\n   \n   The critical value is determined by how you set alpha and beta.\n\n## Week 2: Overview\n\nLikelihood approaches and Bayesian statistics quantify relative levels of evidence, with the Bayesian approach also incorporating prior information. \nReadings: \nThe go-to book about likelihoods is by Royall (but regrettably, it is quite expensive).\n\nRoyall, R. (1997). Statistical Evidence: A Likelihood Paradigm. London?; New York: Chapman and Hall/CRC.\n\nHe provides a summary here:\n\nRoyall, R. (2004). The likelihood paradigm for statistical evidence. The nature of scientific evidence. Statistical, philosophical, and empirical considerations. University of Chicago Press, Chicago, Illinois, 119-152.\n\nA nice tutorial introduction is given by Blume:\n\nBlume, J. D. (2002). Likelihood methods for measuring statistical evidence. Statistics in Medicine, 21(17), 2563-2599.\n\nAnd an applied book-length treatment can be found in:\n\nPawitan, Y. (2001). In all likelihood: statistical modelling and inference using likelihood. Oxford?: New York: Clarendon Press?; Oxford University Press.\n\nLecture 2.2 and Lecture 2.3\n\nA good introduction to Bayesian statistics for the social science is provides by Jackman (Chapter 2 is closely related to Assignment 2.2).\n\nJackman, S. (2009). Bayesian analysis for the social sciences. Chichester, U.K: Wiley.\n\nAn article highlighting some of the strengths of Bayesian statistics is provided by Wagenmakers and colleagues. It specifically discusses the studies by Daryl Bem on pre-cognition we have described, and also touches on the need to distinguish confirmatory and exploratory research (see Lecture 3.3):\n\nWagenmakers, E.-J., Wetzels, R., Borsboom, D., & van der Maas, H. l. (2011). Why Psychologists Must Change the Way They Analyze Their Data: The Case of Psi: Comment on Bem (2011). Journal of Personality and Social Psychology, 100(3), 426-432.\n\nZoltan Dienes has an accessible introduction to how Bayes factors change the way you would make scientific inferences:\n\nDienes, Z. (2016). How Bayes factors change scientific practice. Journal of Mathematical Psychology. http://www.sciencedirect.com/science/article/pii/S0022249615000607\n\nAnd a great tutorial handbook on Bayesian data analysis that focusses on Bayesian estimation instead of Bayesian hypothesis testing is written by Kruschke:\n\nKruschke, J. (2010). Doing Bayesian data analysis: A tutorial introduction with R. Academic Press.\n\n### Lecture 2.1: Likelihoods\n\nLikelihood = function of parameter given the data, so you can plot how likely something is given the data. \n\nE.g. flip a coin 10 times and get 8. So for a theta of 0.8, meaning that if you flipped it a million times, you'd get 800K heads, you can calculate the likelihood given the data (the ten coin flips). You get a likelihood of 0.30. You can also calculate it for other values of theta, such as 0.7 which has a likelihood of 0.23 given the data. The likelihood decreases as you move away from the data you observed. \n\nTypically plot likelihood against theta and see the likelihood distribution. \n\nLikelihood ratio = likelihood under H1 over likelihood under H0.\nE.g. divide likelihood of theta of 0.8 by likelihood of theta of 0.5; gives ratio of 6.87. (Compare hypothesis that it's biased to 0.8 to hypothesis that it's a fair coin.) Compares likelihood of two hypotheses. \n\nLikelihood ratio of 8 = moderately strong evidence; 32 = strong evidence\n\nLikelihood ratio gives relative evidence between two hypotheses -- both may still be extremely unlikely and then even if one is 100000X more likely than the other, they may both be irrelevant if both have a tiny likelihood compared to another hypothesis that is actually true. \n\nCalculating likelihood of observing the statistical results you observed from a series of experiments: \nH0 = no significant effect = alpha = theta = 0.05 (bc you'll get significance 5% of time)\nH1 = significant effect = power = theta = 0.8\n\nLikelihood of observing two significant studies out of three performed: \n   Under the assumption that H0 is true:\n      0.05 * 0.05 * 0.95 = 0.0024\n   \n   Under the assumption that H1 is true: \n      0.8 * 0.8 * 0.2 = 0.128\n\n   Likelihood ratio = 0.128 / 0.0024 = 54 times more probable that H1 is true\n\n   Observation: multiple studies should give mixed results when H1 is true and you have 80% power -> 0.8 * 0.8 * 0.8 = 0.51 means you'll find three significant results from three studies done with 80% power only 50% of the time.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1476303542377.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "999811884",
    "id" : "1F940D3A",
    "lastKnownWriteTime" : 1476806146,
    "last_content_update" : 1476806146791,
    "path" : "H:/Courses/Statistical inference - Coursera/notes.md",
    "project_path" : "notes.md",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "markdown"
}