{
    "collab_server" : "",
    "contents" : "# Load pwr package to easily calculate the statistical power\nif(!require(pwr)){install.packages('pwr')}\nlibrary(pwr)\n# Disable scientific notation (1.05e10)\noptions(scipen = 999)\n# Set number of simulations\nnSims  <-  100000 # number of simulated experiments\n\n# Mean IQ score in the sample (will be compared with 100 in a one-sample t-test)\nM <- 115\n# sample size of the simulated data\nn <- 8 \n# SD of the simulated data\nSD <- 15 \n\n# With a mean difference of 6, and SD of 15, and a sample size of 26, the test \n# has 50% power)\n\np <- numeric(nSims) # set up empty variable to store all simulated p-values\nbars <- 100\n\n# Run simulation\nfor(i in 1:nSims){ # for each simulated experiment\n   # Simulate data with specified mean, standard deviation, and sample size\n   x <- rnorm(n = n, mean = M, sd = SD) \n   # perform the t-test against mu (set to value you want to test against)\n   z <- t.test(x, mu = 100)\n   # get the p-value and store it\n   p[i] <- z$p.value \n}\n\n# Check power by summing significant p-values and dividing by number of \n# simulations\n(sum(p < 0.05) / nSims) # power\n# Calculate power formally by power analysis\n# determines M when power > 0. When power = 0, will set  M = 100.\npower <- pwr.t.test(d = (M - 100) / SD, n = n, sig.level = 0.05,\n   type = \"one.sample\", alternative = \"two.sided\")$power \n\n# Plot figure\n# png(file = \"P-valueDist.png\", width = 4000, height = 3000, , units = \"px\", \n#     res = 500)\n# change white-space around graph\nop <- par(mar = c(5, 7, 4, 4)) \nhist(p, breaks = bars, xlab = \"P-values\", ylab = \"number of p-values\\n\", \n   axes = FALSE, main = paste(\"P-value Distribution with\", \n      round(power * 100, digits = 1), \"% Power\"),\n   col = \"grey\", xlim = c(0, 0.05),  ylim = c(0, 10000))\naxis(side = 1, at = seq(0, 1, 0.1), labels = seq(0, 1, 0.1))\naxis(side = 2, at = seq(0, nSims, nSims/4), labels = seq(0, nSims, nSims / 4), \n   las = 2)\nabline(h = nSims / bars, col = \"red\", lty = 3)\n# dev.off()\n\n# ? Daniel Lakens, 2016. \n# This work is licensed under a Creative Commons \n# Attribution-NonCommercial-ShareAlike 4.0 International License. \n# https://creativecommons.org/licenses/by-nc-sa/4.0/\n\n\n# Q1: Since the statistical power is the probability of observing a \n# statistically significant result, if there is a true effect, we can also see \n# the power in the figure itself. Where?\n#     A) We can calculate the number of p-values larger than 0.5, and divide \n#        them by the number of simulations.\n#     *B)* We can calculate the number of p-values in the first bar (which \n#        contains all ‘significant’ p-values from 0.00 to 0.05) and divide the \n#        p-values in this bar by the total number of simulations.\n#     C) We can calculate the difference between p-values above 0.5 minus the \n#        p-values below 0.5, and divide this number by the total number of \n#        simulations.\n#     D) We can calculate the difference between p-values above 0.5 minus the \n#        p-values below 0.05, and divide this number by the number of \n#        simulations. \n\n# Q2: Change the sample size in line 10 from n <- 26 to n <- 51. Run the \n# simulation by selecting all lines and pressing CTRL+Enter. What is the power \n# in the simulation now that we have increased the sample size from 26 people \n# to 51 people?\n#     A) 55% \n#     B) 60% \n#     *C)* 80%\n#     D) 95%\n\n# Q3) If you look at the distribution of p-values, what do you notice?\n#     A) The p-value distribution is exactly the same as with 50% power\n#     *B)* The p-value distribution is much steeper than with 50% power\n#     C) The p-value distribution is much flatter than with 50% power\n#     D) The p-value distribution is much more normally distributed than with \n#        50% power\n\n# Q4) What would happen when there is no true difference between our simulated \n# samples and the average IQ score? In this situation, we have no probability \n# to observe an effect, so you might say we have ‘0 power’. Some people prefer \n# to say power is not defined when there is no true effect. I tend to agree, but\n# we can casually refer to this as 0 power. Change the mean IQ score in the \n# sample to 100 (set M<-106 to M<-100 in line 9) There is now no difference \n# between the average IQ score, and the mean IQ in our simulated sample. Run the\n# script again. What do you notice?\n#     A) The p-value distribution is exactly the same as with 50% power\n#     B) The p-value distribution is much steeper than with 50% power\n#     *C)* The p-value distribution is basically completely flat (ignoring some \n#        minor variation due to random noise in the simulation)\n#     D) The p-value distribution is normally distributed\n\n# Q5) Look at the leftmost bar in the plot, and look at the frequency of \n# p-values in this bar. What is the formal name for this bar?\n#     A) The power (or true positives)\n#     B) The true negatives\n#     *C)* The Type 1 error (or false positives)\n#     D) The Type 2 error (or false negatives)\n\n# Q6) The plot from the last simulation tells you we have 90.5% power. This \n# is the power if we use an alpha of 5%. But we can also use an alpha of 1%. \n# What is the statistical power we have in the simulated studies when we \n# would use an alpha of 1%, looking at the graph? Pick the answer closest to \n# the answer from your simulations.\n#     A) ±90%\n#     *B)* ±75%\n#     C) ±50%\n#     D) ±5%\n\n# Q7) When you know you have very high (e.g., 98%) power for the smallest \n# effect size you care about, and you observe a p-value of 0.045, what is \n# the correct conclusion?\n#     A) The effect is significant, and provides strong support for the \n#        alternative hypothesis.\n#     B) The effect is significant, but it is without any doubt a Type 1 error.\n#     C) With high power, you should use an alpha level that is smaller than \n#        0.05, and therefore, this effect can not be considered significant.\n#     *D)* The effect is significant, but it is more likely that the null-\n#        hypothesis is true, than that the alternative hypothesis is true.\n\n# Q8) Play around with the sample size and the mean IQ in the group (lines 9 and\n# 10, and thus, with the statistical power in the simulated studies). Look at \n# the simulation result for the bar that contains p-values between 0.04 and \n# 0.05. [...] At the very best, how much more likely is a p-value between 0.04 \n# and 0.05 to come from a p-value distribution representing a true effect, than \n# it is to come from a p-value distribution when there is no effect? [...]\n#     A) At best, p-values between 0.04 and 0.05 are equally likely under the \n#        alternative hypothesis, and under the null hypothesis.\n#     *B)* At best, p-values between 0.04 and 0.05 are approximately 4 times  \n#        more likely under the alternative hypothesis, than under the null \n#        hypothesis.\n#     C) At best, p-values between 0.04 and 0.05 are ±10 times more likely under\n#        the alternative hypothesis, than under the null hypothesis.\n#     D) At best, p-values between 0.04 and 0.05 are ±30 times more likely under\n#        the alternative hypothesis, than under the null hypothesis\n\n\n\n\n",
    "created" : 1476302280330.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1309886951",
    "id" : "D4A4BF38",
    "lastKnownWriteTime" : 1476304856,
    "last_content_update" : 1476304856759,
    "path" : "H:/Courses/Statistical inference - Coursera/hw1.R",
    "project_path" : "hw1.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}